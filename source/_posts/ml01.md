---
title: Machine Learning Note 01
toc: true
date: 2020-03-18 15:57:05
categories: ml
keywords: ml-note
tags: 
- ml
- note
---

## 前言
這個學期下定決心要跟著進度把李宏毅機器學習影片看完並且寫完 15 個作業！
於是想說可以邊寫個筆記來記錄一下 :P
還有揪了以前交大的同學一起努力一起彼此督促，避免耍廢。

<!--more-->

先貼一下這學期的[影片進度與作業對照表](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html)。
{% img /uploads/images/ml01/outline.png 800 'outline' %}

以下是此篇筆記的影片連結：
- [Introduction](https://www.youtube.com/watch?v=c9TwBeWAj_U&feature=youtu.be)
- [Regression](https://www.youtube.com/watch?v=fegAeph9UaA&feature=youtu.be)
- [Basic Concept](https://www.youtube.com/watch?v=D_S6y0Jm6dQ&feature=youtu.be)

接下來就是筆記的內容了！

## What is machine learning?
> 丟輸入給機器，機器找一個合適的 function、並輸出答案。

幾個機器學習的例子：
1. Speech Recognition: 輸入聲音訊號、輸出字
2. Image Recognition: 輸入圖片、輸出這張圖有什麼物件
3. Playing GO: 輸入棋盤上黑子白子現在位址、輸出下一步該下什麼位址
4. Dialogue System: 輸入對機器說的話、輸出回應

## Function Type
1. Regression
    - 讓機器找一個數值
    - ex. 預測隔天某時段的 PM2.5
2. Classification
    - 讓機器做一個選擇 (從兩個或多個 option 中)
    - binary
        - 輸出只有兩種可能 (yes/no)
        - ex. 輸入句子，輸出此句意義是正面/負面
    - multi-class
        - 有 N 種選項，輸出會是其中一種
        - ex. 輸入圖片，輸出這是哪種類型的食物
3. Generation
    - 讓機器學習創造
    - 生成比較複雜、有結構的物件
    - ex. 輸出為翻譯、畫圖等等

## Learning Type
1. Supervised Learning
    - 給機器 labeled training data、以及其 data 對應的答案
    - 給一 loss function $L$，讓機器評估 function 的好壞
        - loss 越小越好，代表越接近理想的 function  
    - 機器會自動找出 loss 最低的 function

2. Reinforcement Learning
    - 不需要給機器正確解答，讓機器自己去摸索。根據學習過程中得到的 feedback 來調整學習策略。
    - ex. 預測圍棋下一步位置：
        - 不需要告訴機器每一個情況最正確落子的位址
        - 讓機器跟自己下或是機器跟別人下
        - 機器自己找出適合的策略
        - 若輸了，機器要自己想辦法去提高正確率
        - 機器輸或贏會是 reward，此 reward 可以引導機器學習的方向

3. Unsupervised Learning
    - 給機器一堆 unlabeled data 去學 :P

## How can machine find out our expected function?
給一函式尋找範圍（Network Atchitecture），讓機器在此範圍搜索就好。
像是只考慮 Linear Function (regression or classification) 或是只考慮 Neural Network (RNN or CNN)。
並且使用 Gradient Descent 此種函示尋找方法。

## Research
1. Explainable AI
    - 機器**解釋**為甚麼選這個答案
2. Adversarial Attack
    - 如果惡意攻擊自動辨識系統會怎樣
    - 故意增加些刻意的雜訊、針對機器的雜訊，導致機器可能會辨識錯誤
3. Network Compression
    - 有個 model 可以辨識很高的正確率，但他很肥
    - 要怎麼縮小 network，使得可以放到手機/edge device 上
4. Anomaly Detection
    - 如果放不同種類的東西、怪怪的東西給系統會怎樣
    - ex. 放一個動漫人物的圖片給一個專門辨識動物的機器，機器能不能回答：我不知道
5. Domain Adversarial Learning
    - 如果訓練資料跟測試資料很像（distribution 很像），那正確率會很高 => 假象 :P
    - 那如果訓練資料跟測試資料分布不一樣的話要怎麼做才能保持一樣高的正確率？
6. Meta Learning
    - Learn to learn => 學習如何學習的能力
    - ex. 讓程式寫另一個程式/發明另一個演算法
    - 現今人類設計的機器學習的方式很沒效率，所以期望機器自己找到有效率的方法
7. Life-long Learning
    - 終身學期，同樣叫做 Continuous Learning, Never Ending Learning, Incremental Learning
    - 讓機器終身學習、不斷學習下去
    - 學好一個東西就繼續學下一個

## Regression
這邊舉一些 Regression 的例子：
1. 股票預測：輸入過去十年各種股票起伏資料等等、輸出明天某股票指數
2. 無人車、自動車：輸入各種 sensor 的 info、輸出方向盤角度
3. 推薦系統：輸入使用者A和商品B、輸出為使用者A購買商品B的可能性
4. 預測寶可夢進化後的 CP 值：輸入某一隻寶可夢、輸出其進化後的 CP 值


以下用寶可夢作為例子：）
<span style="color:INDIANRED">$f(pokemon) = y$</span>

$x_{cp}$：寶可夢進化前的 CP 值
$x_s$：寶可夢屬於哪個物種 ex. 妙挖種子
$x_{hp}$：寶可夢生命值
$x_w$：寶可夢的重量
$x_h$：寶可夢的高度
$y$：進化後的 CP 值

## Machine Learning Three Steps
> 機器學習很 basic 的三步驟！

1. 找一 model/function set
2. 定義 function set 中某一 function，並估算其好壞
3. 找出最好的 function

### (I) Find a Function Set
> 要找 function set (model)

Q：那，這個 model 應該要長怎樣呢？
A：應該要是 input 為寶可夢，output 為進化後的 CP 值的 function

這邊先假設一個很簡單的 model：
<span style="color:INDIANRED">$y = b + w \cdot x_{cp}$</span>
- 其中 w 與 b 這兩個參數可以是任何 value
- 填入不同的數字，就得到不同的 function :P 
- ex. $f_1 = 10 + 9.0 \cdot x_{cp}$、$f_2 = 9.8 + 9.2 \cdot x_{cp}$
    - 有 $\infty$ 種可能的 function

這個很簡單的 model 為 Linear Model：<span style="color:#FF5733">$y=b+\sum{w_ix_i}$</span>
- $x_i:$ an attribute of input x（feature）
- $w_i$ 是 weight
- $b$ 是 bias 

#### Collecting training data
> 再找 function 之前，要先蒐集 training data
1. Squirtle => Wartortle
    - input $x^1$ 為 Squirtle；output $\hat{y}^1$ 為 979
2. Eevee => Sparky
    - input $x^2$ 為 Eevee；output $\hat{y}^2$ 為 1420
3. ........ 假設蒐集到 10 隻 pokemon 的 data

有了 training data，就要定義 function 的好壞。

### (II) Goodness of Function
> 定義 function 好壞

定義 Loss Function $L$：<span style="color:#900C3F">$L(f)=L(w,b)$</span>
- input: a function
- output: how bad this function is

也就是說，loss function 在衡量參數的好壞。

可以自己定義 loss function 的，但是有比較常見的作法 --- **估測誤差**：
<span style="color:#F08080">$L(f)=\sum\limits_1^{10} {(\hat{y}^n - (b + w * x_{cp}^n))^2}$</span>
- $\hat{y}^n:$ the real y
- $(b+w \cdot x_{cp}^n):$ estimated y based on input function

### (III) Best Function
> 在上一步驟已經定好 loss function，可以衡量每一個 function 的好壞了
> 接下來，就是要從這個 set 裡面，挑選出最好的一個 function

<span style="color:#BA4A00">$f^* = \arg\min\limits_f L(f)$</span>
<span style="color:#BA4A00">$w^\*, b^\* = \arg\min\limits_{w,b} L(w,b))$</span>

所以，要做的事情是就是找到一組 $w$ & $b$ 使得 loss 為最小。
- 用線性代數可以找到 Closed-Form Solution
- 或是用 Gradient Descent

## Gradient Descent
> 只要 L 可微分，就能拿來找可能比較好的 solution

首先，先來看比較簡單的情況。
若 loss function 只有一個參數，Gradient Descent 要如何求解？

### a) Loss function with only one parameter $w$
> $w^* = \arg \min\limits_w L(w))$

以下步驟：
1. Randomly pick an initial value $w^0$
2. Compute $\frac{dL}{dw}|_{w= w^0}$ 
    - 計算切線斜率
    - 若為負，表示左邊 loss 比右邊 loss 高 => 增加 $w$ 值
    - 若為正，表示右邊 loss 比較高 => 減少 $w$ 值
3. Update: <span style="color:#3C9954">$w^1 \gets w^0 - \eta *\dfrac{dL}{dw_0}$</span>
4. Repeat 2), 3) ...
    - Compute $\frac{dL}{dw}|_{w=w^1}$
    - Update: $w^2 \gets w^1 - \eta *\dfrac{dL}{dw_1}$
    - ...
5. Continue T times, then get the local min :)


以上**更新的幅度**有多大取決於兩件事情：
1. 微分值 $\frac{dL}{dw}$ 有多大
    - 如果越大表示越陡峭，則移動距離越大；反之越小
2. 常數項 learning rate $\eta$
    - 是事先定好的數字；若定越大，參數更新的幅度就越大


經過非常多次 iteration 更新參數後，會到 local min 的地方：
- 也就是微分是 0 的地方
- 但幸運的是，在 linear regression 上沒有 local min :P 

若 $L$ 有兩個參數呢 $w, b$ ？ 

#### 在進入情境 b 之前，先複習一下偏微分ㄅㄅㄅ :P
由於 <span style="color:#F0B27A">$L = \sum{(\hat{y}^n - (b + w * x_{cp}^n))^2}$</span>，所以：
1. $w$ 對 $L$ 的偏微分：
    - $\dfrac{\partial L}{\partial w}|_{w=w^0,b=b^0} = \sum{2(\hat{y}^n - (b+w*x_{cp}^n))*(-x_{cp}^n)}$
2. $b$ 對 $L$ 的偏微分：
    - $\dfrac{\partial L}{\partial b}|_{w=w^0,b=b^0} = \sum{2(\hat{y}^n - (b+w*x_{cp}^n))*(-1)}$

Q：那，Gradient $\nabla L$ 是什麼呢？
A：把 $w$ 對 $L$ 的偏微分和 $b$ 對 $L$ 的偏微分排成一個 vector
{% img /uploads/images/ml01/gd.png 200 'gd' %}

### b) Loss function with two parameters $w, b$
> $w^*, b^* = \arg \min\limits_{w,b} L(w,b))$

以下步驟其實大同小異：
1. Randomly pick an initial value $w^0, b^0$
2. Compute 
    - $\dfrac{\partial L}{\partial w}|_{w=w^0,b=b^0}$
    - $\dfrac{\partial L}{\partial b}|_{w=w^0,b=b^0}$
3. Update
    - <span style="color:#0DB8D3">$w^1 \gets w^0 - \eta * \dfrac{\partial L}{\partial w}|_{w=w^0,b=b^0}$</span> 
    - <span style="color:#00A6F4">$b^1 \gets b^0 - \eta * \dfrac{\partial L}{\partial b}|_{w=w^0,b=b^0}$</span> 
4. Repeat 2), 3) ...
    - Compute: 
        - $\dfrac{\partial L}{\partial w}|_{w=w^1,b=b^1}$
        - $\dfrac{\partial L}{\partial b}|_{w=w^1,b=b^1}$
    - Update: $w^2$ and $b^2$
    - ...
5. Continue T times, then get the local min :D

關於 local min 的問題：
Q：Gradient Descent 可以找到 local min，但會不會找不到 global min？
A：但是！In linear regression, loss function $L$ 是 convex 的，它並沒有 local min optimal，他就是 global min！

## Improvement
> 得到 model 之後，使用在 testing data，並試著改善。

### Model Complexity
假設經過上述 3 步驟後，得到最終 model 為 $y=-188.4+2.7 \cdot x_{cp}$。

我們又抓了另外 10 隻 pokemon 當成 testing data，然後計算每個 data point 離 function 最近的距離 $e^i$，也就是 error。

假設：
1. average error on training data $= 31.9$
2. average error on testing data $= \sum\limits_n^{10}e^n = 35.0$

其實可以看的出來 testing data 與 training data 的分布是差不多的，因為 performance 感覺起來是不相上下的。

從下圖（testing data）結果看來，model 可能不是直線這麼簡單，可能需要改善。
{% img /uploads/images/ml01/res.png 300 'result' %}

Q：那要如何改善呢？
A：**需要複雜一點的 model，像是引入二次式之類的。**

於是重新設計 model 為 <span style="color:#F39C12">$y=b+w_1 \cdot x_{cp}+w_2 \cdot (x_{cp})^2$</span>。
然後再重複剛剛的步驟，用 Gradient Descent 找出最好的參數。

假設，找到的最好的 function 是 $y = -10.3 + x_{cp} + 2.7 \cdot 10^{-3} \cdot (x_{cp})^2$，並計算 testing data 的 error。
1. average error on training data $= 15.4$
2. average error on testing data $= 18.4$

觀察下圖（testing data）得知，testing data 與二次式更 fit 一點。
{% img /uploads/images/ml01/2t.png 300 'improvement' %}

> 但是！！也不能太太太複雜，否則會適得其反。

像是若重新設計 model 為四次式 <span style="color:#EC7063">$y=b+w_1 \cdot x_{cp}+w_2 \cdot (x_{cp})^2 + w_3 \cdot (x_{cp})^3 + w_4 \cdot (x_{cp})^4$</span>，找到的最好 model 之後，並計算 error。
1. average error on training data $= 14.9$
2. average error on testing data $= 28.8$

下圖為 model complexity 與 error 之間的比較。
{% img /uploads/images/ml01/compare.png 400 'compare' %}

可以看到 model 複雜度越高，對 training data 的 error 會越低，但對 testing data 不減反增，這就是 **Overfitting**。

所以，選擇適當的 model 就好，不需要太複雜。

### Hidden Factors
蒐集了更多筆資料之後，可以發現，物種這個 factor 深深影響著 output，每個物種的 model 貌似長的都不太一樣。
{% img /uploads/images/ml01/100.png 300 'more data' %}
 
只考慮 $x_{cp}$ 是不夠的，於是重新設計 model。
1. if $x_s =$ Pidgey: $y = b_1 + w_1 \cdot x_{cp}$
2. if $x_s =$ Weedle: $y = b_2 + w_2 \cdot x_{cp}$
3. if $x_s =$ Caterpie: $y = b_3 + w_3 \cdot x_{cp}$
4. if $x_s =$ Eevee: $y = b_4 + w_4 \cdot x_{cp}$

Q：阿要怎麼把 if 放到 linear model 裡面？
A：改寫成以下 linear function

<span style="color:#F8C471"> $y = b_1 \cdot \delta(x_s = Pidgey) + w_1 \cdot \delta(x_s = Pidgey) \cdot x_{cp}$
$\mbox{ }\mbox{ }\mbox{ } +b_2 \cdot \delta(x_s = Weedle) + w_2 \cdot \delta(x_s = Weedle) \cdot x_{cp}$
$\mbox{ }\mbox{ }\mbox{ } +b_3 \cdot \delta(x_s = Caterpie) + w_3 \cdot \delta(x_s = Caterpie) \cdot x_{cp}$
$\mbox{ }\mbox{ }\mbox{ } +b_4 \cdot \delta(x_s = Eevee) + w_4 \cdot \delta(x_s = Eevee) \cdot x_{cp}$
</span>


其中 delta function $\delta$ 的值為 
- 1, if $x_s$ = Pidgey
- 0, otherwise

假設目前物種為 Pidgey，則看到的 function 會為 $y = b_1 + w_1 \cdot x_{cp}$；也就是各物種的 function 都不一樣。

再用 Gradient Descent 找到最好的參數、並且計算 error：
1. average error on training data $= 3.8$
2. average error on testing data $= 14.3$ 

結果為下圖（testing data），比剛剛的結果都更好。
{% img /uploads/images/ml01/improv.png 300 'improvement' %}

但是好像還有其他地方能夠改善，可能會是 $x_h, x_w, x_{hp}$ 等等其他的因素。 
如果沒有 domain knowledge，不知道那個 attribute 比較跟結果有關，則可以通通丟進去設計 model。
1. if $x_s =$ Pidgey: $y' = b_1 + w_1 \cdot x_{cp} + w_5 \cdot (x_{cp})^2$
2. if $x_s =$ Weedle: $y' = b_2 + w_2 \cdot x_{cp} + w_6 \cdot (x_{cp})^2$
3. if $x_s =$ Caterpie: $y' = b_3 + w_3 \cdot x_{cp} + w_7 \cdot (x_{cp})^2$
4. if $x_s =$ Eevee: $y' = b_4 + w_4 \cdot x_{cp} + w_8 \cdot (x_{cp})^2$

得到最終 model 為：
<span style="color:#F8C471"> $y = y' + w_9 \cdot x_{hp} + w_{10} \cdot (x_{hp})^2 + w_{11} \cdot x_h + w_{12} \cdot (x_h)^2 + w_{13} \cdot x_w + w_{14} \cdot (x_w)^2$ </span>

計算 error：
1. average error on training data $= 1.9$
2. average error on testing data $= 102.3$

在 testing data 的結果太糟糕啦～～～～～
可以用 **regularization** 解決！

## Regularization
> 重新定義 loss function $L$，把一些 knowledge 放進去，找到比較好的 function。

一開始的 loss function 只考慮了 prediction 的 error 這件事：
$y = b + \sum w_i x_i$
$L = \sum\limits_n(\hat{y}^n - (b + \sum w_i x_i))^2$

Regularization 就是加上 <span style="color:#F08080">額外的 term</span> 來改善 loss function：
$L = \sum\limits_n \left ( \hat{y}^n - \left ( b + \sum w_i x_i \right ) \right )^2 +$ <span style="color:#F08080"> $\lambda \sum (w_i)^2$</span>

現在分別看兩項的意思：
1. prediction error：很直觀，錯誤越少越好
2. $\lambda \sum (w_i)^2$：參數的值越小越接近 0 越好

Q：WHY 參數越小越好？
A：參數越接近 0，function 也就越平滑，也就是說 output 對 input 的變化越不敏感。

$y = b + \sum w_i x_i$
當 input 增加了 $\Delta x_i$，output 會增加 $w_i \Delta x_i$。
所以當 input 改變，$w_i$ 越小，output 越不容易有變化。

Q：為何喜歡比較 smooth 的 function？
A：假設 noise 影響了 input，function 會受到較少的影響，給我們比較好的結果。

下圖為加入 regularization 的實驗結果：
{% img /uploads/images/ml01/reg.png 400 'regularization' %}

當 $\lambda$ 越大，考慮 smooth 那項 term 的影響力越大，所以找到的 function 就越平滑。

當 $\lambda$ 越大，會呈現兩種現象：
1. training data error 越大
2. testing data error 可能越小
    - 但太大又會反升，例如平滑到像是一條直線 :O 

Q：為何 function 越平滑，training data error 會越大？
A：因為越傾向於考慮 w 的數值，減少考慮 error。

Q：function 要有多 smooth？
A：調 $\lambda$ 得到最好的 model

> note:: 在做 regularization 的時候不用考慮 bias $b$。
> 因為調整 bias 值只是上下移動 function，對平滑值沒有關係。

## Where does the function come from?
> error 有兩個來源：bias、variance
> 所以要找出 error 來源，才能對症下藥！

只有 God 知道理想的 function $\hat{f}$ 長怎樣，而我們只能從 traning data 找到我們理想中的 $f^*$。

所以 $\hat{f}$ 與 $f^*$ 之間的差距就是 error，來自於 bias 或 variance。

## Bias and Variance of Estimator
> Bias of Estimator

假設現在有一 variable $x$：
- the mean of $x$ is $\mu$
- the variance of $x$ is $\delta^2$

若要估測 mean $\mu$ 的話：
1. 首先先 sample N 個點: ${x^1, x^2, ..., x^N}$
2. 再算 N 個點的平均值 $m = \frac{1}{N} \sum\limits_n x^n \neq \mu$ （不見得一樣）
3.  於是做重複多次1. 2. 步驟，得到多次 $m_i$
4.  再算期望值 $E[m] = E[\frac{1}{N} \sum\limits_n x^n] = \frac{1}{N} \sum\limits_nE[x^n] = \mu$

所以可以用 m 來 estimate $\mu$，m 是 unbiased 的，因為其期望值會正好與 $\mu$ 相等！

若 N 較大，m 會較集中；反之較分散。

> Variance of Estimator

若要估測 variance $\delta^2$ 的話：
1. $s^2 = \frac{1}{N} \sum\limits_n (x^n-m)^2$
2. 同上面 sample 多次、得到多個 m、算出多個 $s_i$
3. 期望值 $E[s^2] = \frac{N-1}{N} \delta^2 \neq \delta^2$

$s^2$ 為 biased estimator，因為其期望值並不會等於$\delta^2$。

若 N 較大，$s^2$ 與 $\delta^2$ 其之間差距會更小。

## Estimate the real function $\hat{f}$
取決於兩件事：
1. 是否瞄準正中心 => bias
    - 做多次實驗得到多個 $f^\*$，算出期望值 $E[f^\*] = \bar{f}$
    - 若 $\bar{f}$ 不是散佈於 $\hat{f}$ 附近的話代表有偏差 bias。
2. 偏移 => variance
    - 每次 $f^*$ 與 $\bar{f}$ 的距離

{% img /uploads/images/ml01/bv.png 300 'bias and variance' %}
有四種情況：
- 左上：bias 小、vaiance 小。
    - 此為最理想的狀況。
- 左下：bias 大、variance 小。
    - 每次找的 $f^*$ 都很像，但都集中在錯誤位置。
- 右上：bias 小、variance 大。
    - 瞄準對，但每次 $f^*$ 都差很多。
- 右下：bias 多、variance 大。

## Model vs Variance
> 以 model 複雜度來說，越簡單 variance 越小。

ex. $y = b + w * x_{cp}$ vs $y = b + w_1 * x_{cp} + w_2 * (x_{cp})^2 ...$

{% img /uploads/images/ml01/mv.png 400 'model and variance' %}

Q：WHY?
A：因為越簡單的 model 受到不同 data 的影響較小。

## Model vs Bias
> 以 model 複雜度來說，越簡單 bias 越大。

$E[f^*] = \bar{f}$

若 bias 大，表示 $\bar{f}$ 與 $\hat{f}$ 有距離。
若 bias 小，表示 $\bar{f}$ 與 $\hat{f}$ 是靠近的。

1. black curve: the true function $\hat{f}$
2. red curves: 5000 $f^*$
3. blue curve: average of 5000 $f^* = \bar{f}$

若為一次方的 model：
{% img /uploads/images/ml01/mb1.png 300 'model and bias' %}
$\bar{f}$ 與 $\hat{f}$ 較遠。

若為五次方的 model：
{% img /uploads/images/ml01/mb2.png 300 'model and bias' %}
$\bar{f}$ 與 $\hat{f}$ 是接近的。

## Model vs Variance vs Bias
複雜度較小的 model：
- bias 大、但 variance 小

複雜度較大的 model：
- bias 小、但 variance 大

因為 model 為一個範圍的 function set。
當定義好一 model，就已經設定好說最好的 function 就只能從那個範圍內挑出來。

若 model 較簡單，space 較小，可能根本就沒有包含 target $\hat{f}$。
若 model 較複雜，space 較大，比較有機會包含到 target $\hat{f}$。

總結為下圖：
{% img /uploads/images/ml01/summary.png 400 'summary' %}

### Overfitting
若 error 來自於 variance 大：
- Overfitting
- If can fir the training data, but large error on testing data, then probably have large variance

解法：
- **More data**
    - very effective, but not always practical :(
- Generate our own training data
    - ex. image recognition：把圖片旋轉，就多一倍的 data 了
    - ex. speech recognition：變聲器翻轉男女聲
    - ex. language understanding task：英文翻成中文 :P
- Regularization
    - 在原來的 loss function 裡面多加一項，希望參數越小越好、曲線越 smooth 越好
    - 但 bias 可能會變大，所以 weight 要調好，要取得 bias 與 variance 間的平衡

### Underfitting
若 error 來自於 bias 大：
- Underfitting
- If model cannot even fit the training examples, then have large bias

解法： Redesign Model
- Add more features as input
- A more complex model

## Model Selection
> There is usually a trade-off between bias and variance
> Select a model that balances two kinds of error to minimize total error 

WHAT WE SHOULD NOT DO:
我們不該拿手上有的 testing set 去 validate 我們的 model。
因為自己手上擁有的 testing set 會有自己的一個 bias。

所以，要 Cross Validation！

### Cross Validation
把手中有的 training set 分成兩組：
- training set
    - 得出 model1, model2, model3
- validation set
    - validate 出哪一個 model performance 較好 

若假設得出最好的 model 是 model3，還可以 combine training set 與 validation set，並用在 model3 上再 train 一次。

接下來，就用 (public) tesint data 去測試。
**但不建議測完 tesing data 後回去 tune model，因為這樣又會把 testing data 的 bias 考慮進去。**
也就是說，此舉動是 make public testing set better than private testing set；在 public testing set 中的 performance 無法反映在 private testing set 上。

若擔心 validation set 怪怪的，有 bias，則可以做 N-fold Cross Validation。

### N-fold Cross Validation
把 training set 分成 N 份：
- training set (N-1)
- validation set (1)

一直輪流讓其中一份當 validation set。
選出一 model 後，用完整的 training set 再去 train 一次此 model。


Example：
假設現在有 model1, model2, model3，且現在使用 3-fold Cross Validation。
data 被分為 [data0, data1, data2] 三份。

會有三種情況：
1. train = [data0, data1]; val = [data2]
2. train = [data0, data2]; val = [data1]
3. train = [data1, data2]; val = [data0]

分別使用每一種 model，套用在這三種情形，得出每一個 model 的 average error。

假設 model1 表現最好，再用此完整的 training set 去 train model1。

最後，再去測 testing set。

